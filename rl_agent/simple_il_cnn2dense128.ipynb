{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/hpchome/anton95/.conda/envs/pommerman/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n",
      "/gpfs/hpchome/anton95/.conda/envs/pommerman/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, CSVLogger\n",
    "from keras.layers import Input, Dense, Flatten, Convolution2D\n",
    "from keras.models import Model\n",
    "from keras.utils import to_categorical\n",
    "from pommerman.agents import BaseAgent, SimpleAgent\n",
    "from pommerman.configs import ffa_v0_env\n",
    "from pommerman.constants import BOARD_SIZE\n",
    "from pommerman.envs.v0 import Pomme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16384\n",
    "epochs = 400\n",
    "early_stopping = 200\n",
    "\n",
    "log_path = './dagger/logs/il_cnn64_3_dense128'\n",
    "model_path = './dagger/model/il_cnn2dense128/model.h4'\n",
    "train_data_path = './dagger/train_data/'\n",
    "train_data_obs = 'obs.npy'\n",
    "train_data_labels = 'labels.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Logger(object):\n",
    "    \"\"\"Logging in tensorboard without tensorflow ops.\"\"\"\n",
    "\n",
    "    def __init__(self, log_dir):\n",
    "        \"\"\"Creates a summary writer logging to log_dir.\"\"\"\n",
    "        self.writer = tf.summary.FileWriter(log_dir)\n",
    "\n",
    "    def log_scalar(self, tag, value, step):\n",
    "        \"\"\"Log a scalar variable.\n",
    "        Parameter\n",
    "        ----------\n",
    "        tag : basestring\n",
    "            Name of the scalar\n",
    "        value\n",
    "        step : int\n",
    "            training iteration\n",
    "        \"\"\"\n",
    "        summary = tf.Summary(value=[tf.Summary.Value(tag=tag,\n",
    "                                                     simple_value=value)])\n",
    "        self.writer.add_summary(summary, step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, actions, seed=0, save_path=\"./dagger/model/model.h4\", \n",
    "                 log_path='./dagger/logs/', save_best_only=True):\n",
    "        self.log_path = log_path\n",
    "        self.save_path = save_path\n",
    "        self.actions = actions\n",
    "        self.save_best_only = save_best_only\n",
    "        self.rewards = []\n",
    "        self.current_epoch = 0        \n",
    "        self.logger = Logger(self.log_path)        \n",
    "        \n",
    "        self.model = self.create_model(actions)\n",
    "        if not os.path.isdir(os.path.dirname(save_path)):\n",
    "            os.makedirs(os.path.dirname(save_path))            \n",
    "        if os.path.isfile(self.save_path):\n",
    "            try:\n",
    "                print(\"Trying to load model\")\n",
    "                self.model.load_weights(self.save_path)\n",
    "                print(\"Model was loaded successful\")\n",
    "            except:\n",
    "                print(\"Model load failed\")\n",
    "\n",
    "    def create_model(self, actions, input_shape=(13, 13, 17,)):\n",
    "        inp = Input(input_shape)\n",
    "        x = Convolution2D(64, 3)(inp)\n",
    "        x = Convolution2D(64, 3)(x)\n",
    "        x = Convolution2D(64, 3)(x)\n",
    "        x = Flatten()(x)\n",
    "        x = Dense(128, activation='relu')(x)         \n",
    "        out = Dense(actions, activation='softmax')(x)\n",
    "        model = Model(inputs = inp, outputs=out)\n",
    "        model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        return model\n",
    "\n",
    "    def train(self, obs, labels, batch_size=16384, epochs=100, early_stopping = 10):\n",
    "        early_stopping = EarlyStopping(monitor='loss', patience=early_stopping)\n",
    "        checkpoint = ModelCheckpoint(self.save_path, monitor='loss', save_best_only=self.save_best_only)\n",
    "        reduce_lr = ReduceLROnPlateau(monitor='loss', patience=3, factor=0.09, epsilon=0.0001)\n",
    "        logger = CSVLogger(self.log_path + 'log.csv', append=True)\n",
    "        \n",
    "        history = self.model.fit(x=obs, y=labels, batch_size=batch_size, epochs=epochs, verbose=1,\n",
    "                       callbacks=[early_stopping, checkpoint, reduce_lr, logger],\n",
    "                       validation_split=0.2, shuffle=True)\n",
    "        self.model.load_weights(self.save_path)\n",
    "        self.log_history(history)\n",
    "        self.current_epoch += len(history.history['lr'])\n",
    "    \n",
    "    def log_history(self, history):\n",
    "        def log(history, name, text=None):\n",
    "            if text is None:\n",
    "                text = name\n",
    "            for ind, el in enumerate(history[name]):\n",
    "                self.add_log(text, el, self.current_epoch + ind + 1)\n",
    "        log(history.history, 'val_loss')\n",
    "        log(history.history, 'val_acc')\n",
    "        log(history.history, 'loss')\n",
    "        log(history.history, 'acc')\n",
    "        log(history.history, 'lr')\n",
    "\n",
    "    @staticmethod\n",
    "    def featurize(obs):\n",
    "        shape = (BOARD_SIZE, BOARD_SIZE, 1)\n",
    "\n",
    "        def get_matrix(dict, key):\n",
    "            res = dict[key]\n",
    "            return res.reshape(shape).astype(np.float32)\n",
    "\n",
    "        def get_map(board, item):\n",
    "            map = np.zeros(shape)\n",
    "            map[board == item] = 1\n",
    "            return map\n",
    "\n",
    "        board = get_matrix(obs, 'board')\n",
    "\n",
    "        # TODO: probably not needed Passage = 0\n",
    "        rigid_map = get_map(board, 1)               # Rigid = 1\n",
    "        wood_map = get_map(board, 2)                # Wood = 2\n",
    "        bomb_map = get_map(board, 3)                # Bomb = 3\n",
    "        flames_map = get_map(board, 4)              # Flames = 4\n",
    "        fog_map = get_map(board, 5)                 # TODO: not used for first two stages Fog = 5\n",
    "        extra_bomb_map = get_map(board, 6)          # ExtraBomb = 6\n",
    "        incr_range_map = get_map(board, 7)          # IncrRange = 7\n",
    "        kick_map = get_map(board, 8)                # Kick = 8\n",
    "        skull_map = get_map(board, 9)               # Skull = 9\n",
    "\n",
    "        position = obs[\"position\"]\n",
    "        my_position = np.zeros(shape)\n",
    "        my_position[position[0], position[1], 0] = 1\n",
    "\n",
    "        team_mates = get_map(board, obs[\"teammate\"].value) # TODO during documentation it should be an array\n",
    "\n",
    "        enemies = np.zeros(shape)\n",
    "        for enemy in obs[\"enemies\"]:\n",
    "            enemies[board == enemy.value] = 1\n",
    "\n",
    "        bomb_blast_strength = get_matrix(obs, 'bomb_blast_strength')\n",
    "        bomb_life = get_matrix(obs, 'bomb_life')\n",
    "\n",
    "        ammo = np.full((BOARD_SIZE, BOARD_SIZE, 1), obs[\"ammo\"])\n",
    "        blast_strength = np.full((BOARD_SIZE, BOARD_SIZE, 1), obs[\"blast_strength\"])\n",
    "        can_kick = np.full((BOARD_SIZE, BOARD_SIZE, 1), int(obs[\"can_kick\"]))\n",
    "\n",
    "        obs = np.concatenate([my_position, enemies, team_mates, rigid_map,\n",
    "                              wood_map, bomb_map, flames_map,\n",
    "                              fog_map, extra_bomb_map, incr_range_map,\n",
    "                              kick_map, skull_map, bomb_blast_strength,\n",
    "                              bomb_life, ammo, blast_strength, can_kick], axis=2)\n",
    "        return obs    \n",
    "        \n",
    "    def add_log(self, tag, value, step):\n",
    "        self.logger.log_scalar(tag, value, step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isdir(train_data_path):\n",
    "    full_obs = np.load(train_data_path + train_data_obs)\n",
    "    full_labels = np.load(train_data_path + train_data_labels)\n",
    "else:\n",
    "    # Generate training data\n",
    "    training_data, _ = stimulator.stimulate(expert, num_rollouts=initial_rollouts)\n",
    "    full_obs = training_data[0]\n",
    "    full_labels = training_data[1]\n",
    "temp = []\n",
    "for obs in full_obs:\n",
    "    temp.append(Agent.featurize(obs))\n",
    "full_obs = np.array(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the environment\n",
    "config = ffa_v0_env()\n",
    "env = Pomme(**config[\"env_kwargs\"])\n",
    "\n",
    "agent = Agent(env.action_space.n, save_path=model_path, log_path=log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/hpchome/anton95/.conda/envs/pommerman/lib/python3.6/site-packages/keras/callbacks.py:928: UserWarning: `epsilon` argument is deprecated and will be removed, use `min_delta` insted.\n",
      "  warnings.warn('`epsilon` argument is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1005208 samples, validate on 251303 samples\n",
      "Epoch 1/400\n",
      "1005208/1005208 [==============================] - 399s 397us/step - loss: 1.6112 - acc: 0.3663 - val_loss: 1.4328 - val_acc: 0.4069\n",
      "Epoch 2/400\n",
      "1005208/1005208 [==============================] - 297s 295us/step - loss: 1.3894 - acc: 0.4197 - val_loss: 1.4115 - val_acc: 0.4138\n",
      "Epoch 3/400\n",
      "1005208/1005208 [==============================] - 294s 292us/step - loss: 1.3298 - acc: 0.4394 - val_loss: 1.4079 - val_acc: 0.4168\n",
      "Epoch 4/400\n",
      "1005208/1005208 [==============================] - 294s 293us/step - loss: 1.2806 - acc: 0.4568 - val_loss: 1.4132 - val_acc: 0.4159\n",
      "Epoch 5/400\n",
      "1005208/1005208 [==============================] - 293s 292us/step - loss: 1.2444 - acc: 0.4708 - val_loss: 1.3956 - val_acc: 0.4243\n",
      "Epoch 6/400\n",
      "1005208/1005208 [==============================] - 294s 293us/step - loss: 1.2105 - acc: 0.4841 - val_loss: 1.3904 - val_acc: 0.4199\n",
      "Epoch 7/400\n",
      "1005208/1005208 [==============================] - 294s 293us/step - loss: 1.1760 - acc: 0.4985 - val_loss: 1.3705 - val_acc: 0.4311\n",
      "Epoch 8/400\n",
      "1005208/1005208 [==============================] - 295s 293us/step - loss: 1.1423 - acc: 0.5113 - val_loss: 1.3700 - val_acc: 0.4295\n",
      "Epoch 9/400\n",
      "1005208/1005208 [==============================] - 295s 293us/step - loss: 1.1153 - acc: 0.5226 - val_loss: 1.3568 - val_acc: 0.4367\n",
      "Epoch 10/400\n",
      "1005208/1005208 [==============================] - 295s 293us/step - loss: 1.0928 - acc: 0.5329 - val_loss: 1.3860 - val_acc: 0.4289\n",
      "Epoch 11/400\n",
      "1005208/1005208 [==============================] - 294s 293us/step - loss: 1.0767 - acc: 0.5394 - val_loss: 1.3638 - val_acc: 0.4330\n",
      "Epoch 12/400\n",
      "1005208/1005208 [==============================] - 293s 292us/step - loss: 1.0605 - acc: 0.5461 - val_loss: 1.3781 - val_acc: 0.4317\n",
      "Epoch 13/400\n",
      "1005208/1005208 [==============================] - 295s 293us/step - loss: 1.0462 - acc: 0.5524 - val_loss: 1.3723 - val_acc: 0.4369\n",
      "Epoch 14/400\n",
      "1005208/1005208 [==============================] - 295s 293us/step - loss: 1.0316 - acc: 0.5590 - val_loss: 1.3885 - val_acc: 0.4313\n",
      "Epoch 15/400\n",
      "1005208/1005208 [==============================] - 298s 297us/step - loss: 1.0200 - acc: 0.5632 - val_loss: 1.3908 - val_acc: 0.4321\n",
      "Epoch 16/400\n",
      "1005208/1005208 [==============================] - 298s 296us/step - loss: 1.0085 - acc: 0.5684 - val_loss: 1.3943 - val_acc: 0.4370\n",
      "Epoch 17/400\n",
      "1005208/1005208 [==============================] - 299s 297us/step - loss: 0.9976 - acc: 0.5731 - val_loss: 1.4180 - val_acc: 0.4191\n",
      "Epoch 18/400\n",
      "1005208/1005208 [==============================] - 298s 297us/step - loss: 0.9877 - acc: 0.5773 - val_loss: 1.4060 - val_acc: 0.4349\n",
      "Epoch 19/400\n",
      "1005208/1005208 [==============================] - 299s 298us/step - loss: 0.9788 - acc: 0.5807 - val_loss: 1.4449 - val_acc: 0.4140\n",
      "Epoch 20/400\n",
      "1005208/1005208 [==============================] - 298s 297us/step - loss: 0.9698 - acc: 0.5848 - val_loss: 1.4328 - val_acc: 0.4204\n",
      "Epoch 21/400\n",
      "1005208/1005208 [==============================] - 301s 300us/step - loss: 0.9619 - acc: 0.5881 - val_loss: 1.4446 - val_acc: 0.4183\n",
      "Epoch 22/400\n",
      "1005208/1005208 [==============================] - 302s 300us/step - loss: 0.9547 - acc: 0.5909 - val_loss: 1.4567 - val_acc: 0.4139\n",
      "Epoch 23/400\n",
      "1005208/1005208 [==============================] - 298s 297us/step - loss: 0.9487 - acc: 0.5936 - val_loss: 1.4846 - val_acc: 0.4124\n",
      "Epoch 24/400\n",
      " 704512/1005208 [====================>.........] - ETA: 1:23 - loss: 0.9405 - acc: 0.5970"
     ]
    }
   ],
   "source": [
    "agent.train(full_obs, full_labels, batch_size=batch_size, epochs=epochs, early_stopping=early_stopping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
