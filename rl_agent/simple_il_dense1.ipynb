{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, CSVLogger\n",
    "from keras.layers import Input, Dense, Flatten, Convolution2D\n",
    "from keras.models import Model\n",
    "from keras.utils import to_categorical\n",
    "from pommerman.agents import BaseAgent, SimpleAgent\n",
    "from pommerman.configs import ffa_v0_env\n",
    "from pommerman.constants import BOARD_SIZE\n",
    "from pommerman.envs.v0 import Pomme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32769\n",
    "epochs = 400\n",
    "early_stopping = 200\n",
    "\n",
    "log_path = './dagger/logs/il_dense1'\n",
    "model_path = './dagger/model/il_dense1/model.h4'\n",
    "train_data_path = './dagger/train_data/'\n",
    "train_data_obs = 'obs.npy'\n",
    "train_data_labels = 'labels.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Logger(object):\n",
    "    \"\"\"Logging in tensorboard without tensorflow ops.\"\"\"\n",
    "\n",
    "    def __init__(self, log_dir):\n",
    "        \"\"\"Creates a summary writer logging to log_dir.\"\"\"\n",
    "        self.writer = tf.summary.FileWriter(log_dir)\n",
    "\n",
    "    def log_scalar(self, tag, value, step):\n",
    "        \"\"\"Log a scalar variable.\n",
    "        Parameter\n",
    "        ----------\n",
    "        tag : basestring\n",
    "            Name of the scalar\n",
    "        value\n",
    "        step : int\n",
    "            training iteration\n",
    "        \"\"\"\n",
    "        summary = tf.Summary(value=[tf.Summary.Value(tag=tag,\n",
    "                                                     simple_value=value)])\n",
    "        self.writer.add_summary(summary, step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, actions, seed=0, save_path=\"./dagger/model/model.h4\", \n",
    "                 log_path='./dagger/logs/', save_best_only=True):\n",
    "        self.log_path = log_path\n",
    "        self.save_path = save_path\n",
    "        self.actions = actions\n",
    "        self.save_best_only = save_best_only\n",
    "        self.rewards = []\n",
    "        self.current_epoch = 0        \n",
    "        self.logger = Logger(self.log_path)        \n",
    "        \n",
    "        self.model = self.create_model(actions)\n",
    "        if not os.path.isdir(os.path.dirname(save_path)):\n",
    "            os.makedirs(os.path.dirname(save_path))            \n",
    "        if os.path.isfile(self.save_path):\n",
    "            try:\n",
    "                print(\"Trying to load model\")\n",
    "                self.model.load_weights(self.save_path)\n",
    "                print(\"Model was loaded successful\")\n",
    "            except:\n",
    "                print(\"Model load failed\")\n",
    "\n",
    "    def create_model(self, actions, input_shape=(2369,)):\n",
    "        inp = Input(input_shape)        \n",
    "        x = Dense(128, activation='relu')(inp)\n",
    "        out = Dense(actions, activation='softmax')(x)\n",
    "        \n",
    "        model = Model(inputs = inp, outputs=out)\n",
    "        model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        return model\n",
    "\n",
    "    def train(self, obs, labels, batch_size=16384, epochs=100, early_stopping = 10):\n",
    "        early_stopping = EarlyStopping(monitor='loss', patience=early_stopping)\n",
    "        checkpoint = ModelCheckpoint(self.save_path, monitor='loss', save_best_only=self.save_best_only)\n",
    "        reduce_lr = ReduceLROnPlateau(monitor='loss', patience=3, factor=0.8)\n",
    "        logger = CSVLogger(self.log_path + 'log.csv', append=True)\n",
    "        \n",
    "        history = self.model.fit(x=obs, y=labels, batch_size=batch_size, epochs=epochs, verbose=1,\n",
    "                       callbacks=[early_stopping, checkpoint, reduce_lr, logger],\n",
    "                       validation_split=0.2, shuffle=True)\n",
    "        self.model.load_weights(self.save_path)\n",
    "        self.log_history(history)\n",
    "        self.current_epoch += len(history.history['lr'])\n",
    "    \n",
    "    def log_history(self, history):\n",
    "        def log(history, name, text=None):\n",
    "            if text is None:\n",
    "                text = name\n",
    "            for ind, el in enumerate(history[name]):\n",
    "                self.add_log(text, el, self.current_epoch + ind + 1)\n",
    "        log(history.history, 'val_loss')\n",
    "        log(history.history, 'val_acc')\n",
    "        log(history.history, 'loss')\n",
    "        log(history.history, 'acc')\n",
    "        log(history.history, 'lr')\n",
    "\n",
    "    @staticmethod\n",
    "    def featurize(obs):\n",
    "        shape = (BOARD_SIZE, BOARD_SIZE, 1)\n",
    "\n",
    "        def get_matrix(dict, key):\n",
    "            res = dict[key]\n",
    "            return res.reshape(shape).astype(np.float32)\n",
    "\n",
    "        def get_map(board, item):\n",
    "            map = np.zeros(shape)\n",
    "            map[board == item] = 1\n",
    "            return map\n",
    "\n",
    "        board = get_matrix(obs, 'board')\n",
    "\n",
    "        # TODO: probably not needed Passage = 0\n",
    "        rigid_map = get_map(board, 1)               # Rigid = 1\n",
    "        wood_map = get_map(board, 2)                # Wood = 2\n",
    "        bomb_map = get_map(board, 3)                # Bomb = 3\n",
    "        flames_map = get_map(board, 4)              # Flames = 4\n",
    "        fog_map = get_map(board, 5)                 # TODO: not used for first two stages Fog = 5\n",
    "        extra_bomb_map = get_map(board, 6)          # ExtraBomb = 6\n",
    "        incr_range_map = get_map(board, 7)          # IncrRange = 7\n",
    "        kick_map = get_map(board, 8)                # Kick = 8\n",
    "        skull_map = get_map(board, 9)               # Skull = 9\n",
    "\n",
    "        position = obs[\"position\"]\n",
    "        my_position = np.zeros(shape)\n",
    "        my_position[position[0], position[1], 0] = 1\n",
    "\n",
    "        team_mates = get_map(board, obs[\"teammate\"].value) # TODO during documentation it should be an array\n",
    "\n",
    "        enemies = np.zeros(shape)\n",
    "        for enemy in obs[\"enemies\"]:\n",
    "            enemies[board == enemy.value] = 1\n",
    "\n",
    "        bomb_blast_strength = get_matrix(obs, 'bomb_blast_strength')\n",
    "        bomb_life = get_matrix(obs, 'bomb_life')\n",
    "\n",
    "        ammo = obs[\"ammo\"]\n",
    "        blast_strength = obs[\"blast_strength\"]\n",
    "        can_kick = int(obs[\"can_kick\"])\n",
    "\n",
    "        obs = np.concatenate([my_position, enemies, team_mates, rigid_map,\n",
    "                              wood_map, bomb_map, flames_map,\n",
    "                              fog_map, extra_bomb_map, incr_range_map,\n",
    "                              kick_map, skull_map, bomb_blast_strength,\n",
    "                              bomb_life], axis=2).flatten()\n",
    "        obs = np.append(obs, [ammo, blast_strength, can_kick])\n",
    "        return obs\n",
    "        \n",
    "    def add_log(self, tag, value, step):\n",
    "        self.logger.log_scalar(tag, value, step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isdir(train_data_path):\n",
    "    full_obs = np.load(train_data_path + train_data_obs)\n",
    "    full_labels = np.load(train_data_path + train_data_labels)\n",
    "else:\n",
    "    # Generate training data\n",
    "    training_data, _ = stimulator.stimulate(expert, num_rollouts=initial_rollouts)\n",
    "    full_obs = training_data[0]\n",
    "    full_labels = training_data[1]\n",
    "temp = []\n",
    "for obs in full_obs:\n",
    "    temp.append(Agent.featurize(obs))\n",
    "full_obs = np.array(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the environment\n",
    "config = ffa_v0_env()\n",
    "env = Pomme(**config[\"env_kwargs\"])\n",
    "agent = Agent(env.action_space.n, save_path=model_path, log_path=log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1005208 samples, validate on 251303 samples\n",
      "Epoch 1/400\n",
      "1005208/1005208 [==============================] - 432s 429us/step - loss: 1.4548 - acc: 0.4033 - val_loss: 1.4112 - val_acc: 0.4141\n",
      "Epoch 2/400\n",
      "  32769/1005208 [..............................] - ETA: 5:41 - loss: 1.3277 - acc: 0.4546"
     ]
    }
   ],
   "source": [
    "agent.train(full_obs, full_labels, batch_size=batch_size, epochs=epochs, early_stopping=early_stopping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
