{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, CSVLogger, TensorBoard\n",
    "from keras.layers import Input, Dense, Flatten, Convolution2D, BatchNormalization, Activation, Add\n",
    "from keras.models import Model\n",
    "from keras.utils import to_categorical\n",
    "from keras import backend as K\n",
    "from pommerman.agents import BaseAgent, SimpleAgent\n",
    "from pommerman.configs import ffa_competition_env\n",
    "from pommerman.constants import BOARD_SIZE\n",
    "from pommerman.envs.v0 import Pomme\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from sklearn.utils import class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "epochs = 150\n",
    "early_stopping = 7\n",
    "\n",
    "log_path = './dagger/logs/il_go_10res_block/'\n",
    "model_path = './dagger/model/il_go_10res_block/model.h4'\n",
    "train_data_path = './dagger/train_data2/'\n",
    "train_data_obs = 'obs.npy'\n",
    "train_data_preprocessed = 'obs_map.npy'\n",
    "train_data_labels = 'labels.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, actions, seed=0, save_path=\"./dagger/model/model.h4\", \n",
    "                 log_path='./dagger/logs/', save_best_only=True):\n",
    "        K.clear_session()\n",
    "        self.log_path = log_path\n",
    "        self.save_path = save_path\n",
    "        self.actions = actions\n",
    "        self.save_best_only = save_best_only\n",
    "        self.rewards = []\n",
    "        self.current_epoch = 0        \n",
    "        \n",
    "        self.model = self.create_model(actions)\n",
    "        if not os.path.isdir(os.path.dirname(save_path)):\n",
    "            os.makedirs(os.path.dirname(save_path))            \n",
    "        if os.path.isfile(self.save_path):\n",
    "            try:\n",
    "                print(\"Trying to load model\")\n",
    "                self.model.load_weights(self.save_path)\n",
    "                print(\"Model was loaded successful\")\n",
    "            except:\n",
    "                print(\"Model load failed\")\n",
    "        \n",
    "    def get_res_block(self, input):\n",
    "        # Res block 1        \n",
    "        x = Convolution2D(256, 3, padding='same')(input)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation('relu')(x)\n",
    "        x = Convolution2D(256, 3, padding='same')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Add()([input, x])\n",
    "        x = Activation('relu')(x)\n",
    "        return x\n",
    "        \n",
    "    def create_model(self, actions, input_shape=(11, 11, 17,)):\n",
    "        inp = Input(input_shape)\n",
    "        x = Convolution2D(256, 3, padding='same')(inp)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation('relu')(x)\n",
    "        \n",
    "        # Ten residual blocks\n",
    "        for i in range(10):\n",
    "            x = self.get_res_block(x)\n",
    "        \n",
    "        # Output block\n",
    "        # Should be 2 filters\n",
    "        x = Convolution2D(4, 1, padding='same')(x)\n",
    "        x = BatchNormalization()(x)   \n",
    "        x = Activation('relu')(x)\n",
    "        x = Flatten()(x)\n",
    "        out = Dense(actions, activation='softmax')(x)\n",
    "        model = Model(inputs = inp, outputs=out)\n",
    "        model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        return model\n",
    "\n",
    "    def train(self, obs, labels, batch_size=16384, epochs=100, early_stopping = 10, class_weight=None, initial_epoch=0):\n",
    "        early_stopping = EarlyStopping(monitor='loss', patience=early_stopping)\n",
    "        checkpoint = ModelCheckpoint(self.save_path, monitor='loss', save_best_only=self.save_best_only)\n",
    "        reduce_lr = ReduceLROnPlateau(monitor='loss', patience=3, factor=0.8)\n",
    "        logger = CSVLogger(self.log_path + 'log.csv', append=True)\n",
    "        tensorboard = TensorBoard(self.log_path, batch_size=batch_size)\n",
    "        \n",
    "        history = self.model.fit(x=obs, y=labels, batch_size=batch_size, epochs=epochs, verbose=1,\n",
    "                       callbacks=[early_stopping, checkpoint, reduce_lr, logger, tensorboard],\n",
    "                       validation_split=0.15, shuffle=True, class_weight=class_weight, initial_epoch=initial_epoch)\n",
    "        self.model.load_weights(self.save_path)\n",
    "        self.current_epoch += len(history.history['lr'])\n",
    "\n",
    "    @staticmethod\n",
    "    def featurize(obs):\n",
    "        shape = (BOARD_SIZE, BOARD_SIZE, 1)\n",
    "\n",
    "        def get_matrix(dict, key):\n",
    "            res = dict[key]\n",
    "            return res.reshape(shape).astype(np.float32)\n",
    "\n",
    "        def get_map(board, item):\n",
    "            map = np.zeros(shape)\n",
    "            map[board == item] = 1\n",
    "            return map\n",
    "\n",
    "        board = get_matrix(obs, 'board')\n",
    "\n",
    "        # TODO: probably not needed Passage = 0\n",
    "        rigid_map = get_map(board, 1)               # Rigid = 1\n",
    "        wood_map = get_map(board, 2)                # Wood = 2\n",
    "        bomb_map = get_map(board, 3)                # Bomb = 3\n",
    "        flames_map = get_map(board, 4)              # Flames = 4\n",
    "        fog_map = get_map(board, 5)                 # TODO: not used for first two stages Fog = 5\n",
    "        extra_bomb_map = get_map(board, 6)          # ExtraBomb = 6\n",
    "        incr_range_map = get_map(board, 7)          # IncrRange = 7\n",
    "        kick_map = get_map(board, 8)                # Kick = 8\n",
    "        skull_map = get_map(board, 9)               # Skull = 9\n",
    "\n",
    "        position = obs[\"position\"]\n",
    "        my_position = np.zeros(shape)\n",
    "        my_position[position[0], position[1], 0] = 1\n",
    "\n",
    "        team_mates = get_map(board, obs[\"teammate\"].value) # TODO during documentation it should be an array\n",
    "\n",
    "        enemies = np.zeros(shape)\n",
    "        for enemy in obs[\"enemies\"]:\n",
    "            enemies[board == enemy.value] = 1\n",
    "\n",
    "        bomb_blast_strength = get_matrix(obs, 'bomb_blast_strength')\n",
    "        bomb_life = get_matrix(obs, 'bomb_life')\n",
    "\n",
    "        ammo = np.full((BOARD_SIZE, BOARD_SIZE, 1), obs[\"ammo\"])\n",
    "        blast_strength = np.full((BOARD_SIZE, BOARD_SIZE, 1), obs[\"blast_strength\"])\n",
    "        can_kick = np.full((BOARD_SIZE, BOARD_SIZE, 1), int(obs[\"can_kick\"]))\n",
    "\n",
    "        obs = np.concatenate([my_position, enemies, team_mates, rigid_map,\n",
    "                              wood_map, bomb_map, flames_map,\n",
    "                              fog_map, extra_bomb_map, incr_range_map,\n",
    "                              kick_map, skull_map, bomb_blast_strength,\n",
    "                              bomb_life, ammo, blast_strength, can_kick], axis=2)\n",
    "        return obs    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isdir(train_data_path):\n",
    "    if os.path.isfile(train_data_path + train_data_preprocessed):\n",
    "        full_obs = np.load(train_data_path + train_data_preprocessed)\n",
    "    else:\n",
    "        full_obs = np.load(train_data_path + train_data_obs)\n",
    "        temp = []\n",
    "        for obs in tqdm(full_obs):\n",
    "            temp.append(Agent.featurize(obs))\n",
    "        full_obs = np.array(temp)\n",
    "    full_labels = np.load(train_data_path + train_data_labels)\n",
    "else:\n",
    "    # Generate training data\n",
    "    training_data, _ = stimulator.stimulate(expert, num_rollouts=initial_rollouts)\n",
    "    full_obs = training_data[0]\n",
    "    full_labels = training_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.23938972, 0.18678898, 0.16835482, 0.18305518, 0.18544458,\n",
       "       0.03696674], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(full_labels, axis=0) / np.sum(full_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle data\n",
    "indices = np.arange(full_obs.shape[0])\n",
    "np.random.seed(0)\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "full_labels = full_labels[indices]\n",
    "full_obs = full_obs[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the environment\n",
    "config = ffa_competition_env()\n",
    "env = Pomme(**config[\"env_kwargs\"])\n",
    "agent = Agent(env.action_space.n, save_path=model_path, log_path=log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 11, 11, 17)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 11, 11, 256)  39424       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 11, 11, 256)  1024        conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 11, 11, 256)  0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 11, 11, 256)  590080      activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 11, 11, 256)  1024        conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 11, 11, 256)  0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 11, 11, 256)  590080      activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 11, 11, 256)  1024        conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 11, 11, 256)  0           activation_1[0][0]               \n",
      "                                                                 batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 11, 11, 256)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 11, 11, 256)  590080      activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 11, 11, 256)  1024        conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 11, 11, 256)  0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 11, 11, 256)  590080      activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 11, 11, 256)  1024        conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 11, 11, 256)  0           activation_3[0][0]               \n",
      "                                                                 batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 11, 11, 256)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 11, 11, 256)  590080      activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 11, 11, 256)  1024        conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 11, 11, 256)  0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 11, 11, 256)  590080      activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 11, 11, 256)  1024        conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 11, 11, 256)  0           activation_5[0][0]               \n",
      "                                                                 batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 11, 11, 256)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 11, 11, 256)  590080      activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 11, 11, 256)  1024        conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 11, 11, 256)  0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 11, 11, 256)  590080      activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 11, 11, 256)  1024        conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 11, 11, 256)  0           activation_7[0][0]               \n",
      "                                                                 batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 11, 11, 256)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 11, 11, 256)  590080      activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 11, 11, 256)  1024        conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 11, 11, 256)  0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 11, 11, 256)  590080      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 11, 11, 256)  1024        conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 11, 11, 256)  0           activation_9[0][0]               \n",
      "                                                                 batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 11, 11, 256)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 11, 11, 256)  590080      activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 11, 11, 256)  1024        conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 11, 11, 256)  0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 11, 11, 256)  590080      activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 11, 11, 256)  1024        conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 11, 11, 256)  0           activation_11[0][0]              \n",
      "                                                                 batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 11, 11, 256)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 11, 11, 256)  590080      activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 11, 11, 256)  1024        conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 11, 11, 256)  0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 11, 11, 256)  590080      activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 11, 11, 256)  1024        conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 11, 11, 256)  0           activation_13[0][0]              \n",
      "                                                                 batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 11, 11, 256)  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 11, 11, 256)  590080      activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 11, 11, 256)  1024        conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 11, 11, 256)  0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 11, 11, 256)  590080      activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 11, 11, 256)  1024        conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 11, 11, 256)  0           activation_15[0][0]              \n",
      "                                                                 batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 11, 11, 256)  0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 11, 11, 256)  590080      activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 11, 11, 256)  1024        conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 11, 11, 256)  0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 11, 11, 256)  590080      activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 11, 11, 256)  1024        conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 11, 11, 256)  0           activation_17[0][0]              \n",
      "                                                                 batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 11, 11, 256)  0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 11, 11, 256)  590080      activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 11, 11, 256)  1024        conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 11, 11, 256)  0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 11, 11, 256)  590080      activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 11, 11, 256)  1024        conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 11, 11, 256)  0           activation_19[0][0]              \n",
      "                                                                 batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 11, 11, 256)  0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 11, 11, 4)    1028        activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 11, 11, 4)    16          conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 11, 11, 4)    0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 484)          0           activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 6)            2910        flatten_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 11,866,482\n",
      "Trainable params: 11,855,722\n",
      "Non-trainable params: 10,760\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "agent.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.69621482, 0.89227253, 0.98997263, 0.9104723 , 0.89874112,\n",
       "       4.50855708])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cw = class_weight.compute_class_weight('balanced', np.unique(np.argmax(full_labels, axis=1)), np.argmax(full_labels, axis=1))\n",
    "cw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1053338 samples, validate on 185884 samples\n",
      "Epoch 1/150\n",
      "1053338/1053338 [==============================] - 991s 941us/step - loss: 1.0510 - acc: 0.5304 - val_loss: 0.9202 - val_acc: 0.5780\n",
      "Epoch 2/150\n",
      "1053338/1053338 [==============================] - 936s 889us/step - loss: 0.8755 - acc: 0.5950 - val_loss: 0.8856 - val_acc: 0.5922\n",
      "Epoch 3/150\n",
      "1053338/1053338 [==============================] - 937s 890us/step - loss: 0.8328 - acc: 0.6106 - val_loss: 0.8592 - val_acc: 0.5980\n",
      "Epoch 4/150\n",
      "1053338/1053338 [==============================] - 934s 886us/step - loss: 0.8024 - acc: 0.6227 - val_loss: 0.8238 - val_acc: 0.6101\n",
      "Epoch 5/150\n",
      "1053338/1053338 [==============================] - 937s 890us/step - loss: 0.7756 - acc: 0.6344 - val_loss: 0.8213 - val_acc: 0.6133\n",
      "Epoch 6/150\n",
      "1053338/1053338 [==============================] - 934s 887us/step - loss: 0.7499 - acc: 0.6463 - val_loss: 0.7999 - val_acc: 0.6173\n",
      "Epoch 7/150\n",
      "1053338/1053338 [==============================] - 934s 886us/step - loss: 0.7256 - acc: 0.6587 - val_loss: 0.7979 - val_acc: 0.6221\n",
      "Epoch 8/150\n",
      "1053338/1053338 [==============================] - 933s 886us/step - loss: 0.7003 - acc: 0.6710 - val_loss: 0.8153 - val_acc: 0.6208\n",
      "Epoch 9/150\n",
      "1053338/1053338 [==============================] - 933s 886us/step - loss: 0.6755 - acc: 0.6834 - val_loss: 0.8136 - val_acc: 0.6231\n",
      "Epoch 10/150\n",
      "1053338/1053338 [==============================] - 933s 885us/step - loss: 0.6514 - acc: 0.6959 - val_loss: 0.8343 - val_acc: 0.6220\n",
      "Epoch 11/150\n",
      "1053338/1053338 [==============================] - 933s 885us/step - loss: 0.6277 - acc: 0.7077 - val_loss: 0.8479 - val_acc: 0.6236\n",
      "Epoch 12/150\n",
      "1053338/1053338 [==============================] - 932s 885us/step - loss: 0.6058 - acc: 0.7187 - val_loss: 0.8631 - val_acc: 0.6239\n",
      "Epoch 13/150\n",
      "1053338/1053338 [==============================] - 933s 885us/step - loss: 0.5854 - acc: 0.7288 - val_loss: 0.9015 - val_acc: 0.6205\n",
      "Epoch 14/150\n",
      "1053338/1053338 [==============================] - 932s 885us/step - loss: 0.5672 - acc: 0.7377 - val_loss: 0.9051 - val_acc: 0.6238\n",
      "Epoch 15/150\n",
      "1053338/1053338 [==============================] - 932s 885us/step - loss: 0.5504 - acc: 0.7453 - val_loss: 0.9712 - val_acc: 0.6214\n",
      "Epoch 16/150\n",
      "1053338/1053338 [==============================] - 932s 885us/step - loss: 0.5353 - acc: 0.7527 - val_loss: 0.9468 - val_acc: 0.6206\n",
      "Epoch 17/150\n",
      "1053338/1053338 [==============================] - 932s 885us/step - loss: 0.5221 - acc: 0.7590 - val_loss: 0.9808 - val_acc: 0.6231\n",
      "Epoch 18/150\n",
      "1053338/1053338 [==============================] - 932s 885us/step - loss: 0.5108 - acc: 0.7646 - val_loss: 1.0354 - val_acc: 0.6214\n",
      "Epoch 19/150\n",
      "1053338/1053338 [==============================] - 933s 885us/step - loss: 0.5009 - acc: 0.7689 - val_loss: 1.0817 - val_acc: 0.6224\n",
      "Epoch 20/150\n",
      "1053338/1053338 [==============================] - 932s 885us/step - loss: 0.4908 - acc: 0.7737 - val_loss: 1.0694 - val_acc: 0.6217\n",
      "Epoch 21/150\n",
      "1053338/1053338 [==============================] - 932s 885us/step - loss: 0.4819 - acc: 0.7772 - val_loss: 1.0886 - val_acc: 0.6199\n",
      "Epoch 22/150\n",
      "1053338/1053338 [==============================] - 932s 885us/step - loss: 0.4748 - acc: 0.7810 - val_loss: 1.1017 - val_acc: 0.6217\n",
      "Epoch 23/150\n",
      "1053338/1053338 [==============================] - 932s 885us/step - loss: 0.4678 - acc: 0.7844 - val_loss: 1.0780 - val_acc: 0.6207\n",
      "Epoch 24/150\n",
      "1053338/1053338 [==============================] - 932s 885us/step - loss: 0.4609 - acc: 0.7870 - val_loss: 1.1310 - val_acc: 0.6210\n",
      "Epoch 25/150\n",
      "1053338/1053338 [==============================] - 932s 885us/step - loss: 0.4551 - acc: 0.7897 - val_loss: 1.1006 - val_acc: 0.6227\n",
      "Epoch 26/150\n",
      "1053338/1053338 [==============================] - 932s 885us/step - loss: 0.4492 - acc: 0.7922 - val_loss: 1.1820 - val_acc: 0.6179\n",
      "Epoch 27/150\n",
      "1053338/1053338 [==============================] - 932s 885us/step - loss: 0.4449 - acc: 0.7939 - val_loss: 1.1472 - val_acc: 0.6183\n",
      "Epoch 28/150\n",
      "1053338/1053338 [==============================] - 932s 885us/step - loss: 0.4397 - acc: 0.7964 - val_loss: 1.1534 - val_acc: 0.6191\n",
      "Epoch 29/150\n",
      "1053338/1053338 [==============================] - 933s 885us/step - loss: 0.4349 - acc: 0.7980 - val_loss: 1.1846 - val_acc: 0.6189\n",
      "Epoch 30/150\n",
      "1053338/1053338 [==============================] - 932s 885us/step - loss: 0.4310 - acc: 0.7996 - val_loss: 1.1751 - val_acc: 0.6193\n",
      "Epoch 31/150\n",
      "1053338/1053338 [==============================] - 932s 885us/step - loss: 0.4269 - acc: 0.8013 - val_loss: 1.2238 - val_acc: 0.6202\n",
      "Epoch 32/150\n",
      "1053338/1053338 [==============================] - 932s 885us/step - loss: 0.4228 - acc: 0.8029 - val_loss: 1.2699 - val_acc: 0.6196\n",
      "Epoch 33/150\n",
      "1053338/1053338 [==============================] - 932s 885us/step - loss: 0.4193 - acc: 0.8042 - val_loss: 1.2911 - val_acc: 0.6194\n",
      "Epoch 34/150\n",
      "1053338/1053338 [==============================] - 932s 884us/step - loss: 0.4160 - acc: 0.8058 - val_loss: 1.2639 - val_acc: 0.6197\n",
      "Epoch 35/150\n",
      "1053338/1053338 [==============================] - 931s 884us/step - loss: 0.4127 - acc: 0.8070 - val_loss: 1.2622 - val_acc: 0.6190\n",
      "Epoch 36/150\n",
      "1053338/1053338 [==============================] - 932s 885us/step - loss: 0.4102 - acc: 0.8080 - val_loss: 1.3240 - val_acc: 0.6176\n",
      "Epoch 37/150\n",
      "1053338/1053338 [==============================] - 931s 884us/step - loss: 0.4067 - acc: 0.8095 - val_loss: 1.2549 - val_acc: 0.6174\n",
      "Epoch 38/150\n",
      "1053338/1053338 [==============================] - 931s 884us/step - loss: 0.4049 - acc: 0.8102 - val_loss: 1.2561 - val_acc: 0.6193\n",
      "Epoch 39/150\n",
      "1053338/1053338 [==============================] - 931s 884us/step - loss: 0.4015 - acc: 0.8113 - val_loss: 1.3158 - val_acc: 0.6179\n",
      "Epoch 40/150\n",
      "1053338/1053338 [==============================] - 931s 884us/step - loss: 0.3994 - acc: 0.8123 - val_loss: 1.3692 - val_acc: 0.6162\n",
      "Epoch 41/150\n",
      "1053338/1053338 [==============================] - 931s 884us/step - loss: 0.3970 - acc: 0.8130 - val_loss: 1.4382 - val_acc: 0.6179\n",
      "Epoch 42/150\n",
      "1053338/1053338 [==============================] - 931s 884us/step - loss: 0.3952 - acc: 0.8135 - val_loss: 1.3489 - val_acc: 0.6186\n",
      "Epoch 43/150\n",
      "1053338/1053338 [==============================] - 930s 883us/step - loss: 0.3925 - acc: 0.8148 - val_loss: 1.3337 - val_acc: 0.6203\n",
      "Epoch 44/150\n",
      "1053338/1053338 [==============================] - 931s 884us/step - loss: 0.3902 - acc: 0.8153 - val_loss: 1.3727 - val_acc: 0.6186\n",
      "Epoch 45/150\n",
      "1053338/1053338 [==============================] - 931s 884us/step - loss: 0.3886 - acc: 0.8160 - val_loss: 1.3772 - val_acc: 0.6179\n",
      "Epoch 46/150\n",
      "1053338/1053338 [==============================] - 930s 883us/step - loss: 0.3865 - acc: 0.8166 - val_loss: 1.3822 - val_acc: 0.6166\n",
      "Epoch 47/150\n",
      " 748544/1053338 [====================>.........] - ETA: 4:12 - loss: 0.3797 - acc: 0.8201"
     ]
    }
   ],
   "source": [
    "agent.train(full_obs, full_labels, batch_size=batch_size, epochs=epochs, early_stopping=early_stopping,\n",
    "           class_weight=cw, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish\n"
     ]
    }
   ],
   "source": [
    "print(\"finish\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
